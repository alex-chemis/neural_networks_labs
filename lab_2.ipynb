{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from keras import layers, losses, models, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Загрузка и подготовка данных\n",
    "(train_fashion, _), (test_fashion, _) = datasets.fashion_mnist.load_data()\n",
    "(train_mnist, _), (test_mnist, _) = datasets.mnist.load_data()\n",
    "\n",
    "# Нормализация данных и приведение к формату float32\n",
    "train_fashion = train_fashion.astype(\"float32\") / 255.0\n",
    "test_fashion = test_fashion.astype(\"float32\") / 255.0\n",
    "train_mnist = train_mnist.astype(\"float32\") / 255.0\n",
    "test_mnist = test_mnist.astype(\"float32\") / 255.0\n",
    "\n",
    "# Объединение тестовых данных Fashion MNIST и MNIST в одну переменную\n",
    "test_data = np.concatenate((test_fashion, test_mnist), axis=0)\n",
    "\n",
    "# Создание меток\n",
    "fashion_labels = np.ones(test_fashion.shape[0], dtype=bool)  # True для fashion_test_data\n",
    "mnist_labels = np.zeros(test_mnist.shape[0], dtype=bool)        # False для nums_test_data\n",
    "test_labels = np.concatenate((fashion_labels, mnist_labels), axis=0)\n",
    "\n",
    "# Перемешивание данных и меток\n",
    "indices = np.arange(test_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "test_data = test_data[indices]\n",
    "test_labels = test_labels[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 85ms/step - loss: 0.0948\n",
      "Epoch 2/25\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - loss: 0.0263\n",
      "Epoch 3/25\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - loss: 0.0213\n",
      "Epoch 4/25\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 81ms/step - loss: 0.0192\n",
      "Epoch 5/25\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - loss: 0.0178\n",
      "Epoch 6/25\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - loss: 0.0167\n",
      "Epoch 7/25\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - loss: 0.0160\n",
      "Epoch 8/25\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - loss: 0.0155\n",
      "Epoch 9/25\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - loss: 0.0150\n",
      "Epoch 10/25\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 98ms/step - loss: 0.0145\n",
      "Epoch 11/25\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - loss: 0.0142\n",
      "Epoch 12/25\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 81ms/step - loss: 0.0139\n",
      "Epoch 13/25\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - loss: 0.0135\n",
      "Epoch 14/25\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - loss: 0.0133\n",
      "Epoch 15/25\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - loss: 0.0131\n",
      "Epoch 16/25\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - loss: 0.0128\n",
      "Epoch 17/25\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - loss: 0.0126\n",
      "Epoch 18/25\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - loss: 0.0124\n",
      "Epoch 19/25\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - loss: 0.0121\n",
      "Epoch 20/25\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - loss: 0.0120\n",
      "Epoch 21/25\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - loss: 0.0119\n",
      "Epoch 22/25\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 81ms/step - loss: 0.0117\n",
      "Epoch 23/25\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - loss: 0.0116\n",
      "Epoch 24/25\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - loss: 0.0114\n",
      "Epoch 25/25\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - loss: 0.0113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x223bcc700d0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AnomalyDetector(models.Model):\n",
    "    def __init__(self):\n",
    "        super(AnomalyDetector, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = models.Sequential([\n",
    "            layers.Input(shape=(28, 28, 1)),\n",
    "            layers.Conv2D(16, (3, 3), strides=2, padding='same', activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPool2D(),\n",
    "            layers.Conv2D(32, (3, 3), strides=2, padding='same', activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPool2D(),\n",
    "            layers.Flatten(),\n",
    "            layers.Dropout(0.15),  # Dropout для предотвращения переобучения\n",
    "            layers.Dense(64, activation='relu')\n",
    "        ])\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = models.Sequential([\n",
    "            layers.Dense(7 * 7 * 32, activation='relu'),\n",
    "            layers.Reshape((7, 7, 32)),\n",
    "            layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.UpSampling2D((2, 2)),\n",
    "            layers.Conv2DTranspose(16, (3, 3), activation='relu', padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.UpSampling2D((2, 2)),\n",
    "            layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "autoencoder = AnomalyDetector()\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.fit(train_fashion, train_fashion,\n",
    "                epochs=25,\n",
    "                batch_size=512,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step\n",
      "threshold = 0.018819449469447136\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step\n",
      "accuracy = 0.89555\n",
      "precision = 0.9151012698079547\n",
      "recall = 0.872\n"
     ]
    }
   ],
   "source": [
    "def get_loss(model, data):\n",
    "    reconstructions = model.predict(data)\n",
    "    reconstructions_flattened = reconstructions.reshape((reconstructions.shape[0], -1))\n",
    "    data_flattened = data.reshape((data.shape[0], -1))\n",
    "    return losses.mean_squared_error(data_flattened, reconstructions_flattened)\n",
    "\n",
    "train_loss = get_loss(autoencoder, train_fashion)\n",
    "threshold = np.mean(train_loss) + np.std(train_loss)\n",
    "print(f\"threshold = {threshold}\")\n",
    "\n",
    "loss = get_loss(autoencoder, test_data)\n",
    "predict = np.less(loss, threshold)\n",
    "\n",
    "print(f\"accuracy = {accuracy_score(test_labels, predict)}\")\n",
    "print(f\"precision = {precision_score(test_labels, predict)}\")\n",
    "print(f\"recall = {recall_score(test_labels, predict)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
